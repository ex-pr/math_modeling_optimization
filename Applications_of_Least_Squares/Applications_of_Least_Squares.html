<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.555">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Daria Dubovskaia">

<title>Homework 2: Applications of Least Squares</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="Applications_of_Least_Squares_files/libs/clipboard/clipboard.min.js"></script>
<script src="Applications_of_Least_Squares_files/libs/quarto-html/quarto.js"></script>
<script src="Applications_of_Least_Squares_files/libs/quarto-html/popper.min.js"></script>
<script src="Applications_of_Least_Squares_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Applications_of_Least_Squares_files/libs/quarto-html/anchor.min.js"></script>
<link href="Applications_of_Least_Squares_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Applications_of_Least_Squares_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Applications_of_Least_Squares_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Applications_of_Least_Squares_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Applications_of_Least_Squares_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Homework 2: Applications of Least Squares</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Daria Dubovskaia </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="problem-1-online-updating-for-least-squares-and-autoregressive-time-series-models" class="level2">
<h2 class="anchored" data-anchor-id="problem-1-online-updating-for-least-squares-and-autoregressive-time-series-models">Problem 1: Online Updating for Least Squares and Autoregressive Time Series Models</h2>
<p>Many applications of least squares (and other statistical methods) involve , in which data is collected over a time period and the statistical model is updated as new data arrives. If the quantity of data arriving is very large, it may be inefficient or even impossible to refit the entire model on the entire dataset. Instead, we use techniques (often referred to as which take the current model as a starting point and update them to incorporate the new data.</p>
<p>The structure of least squares problems makes them amenable to online updating (sometimes this is called “recursive” least squares). The structure of the problem is as follows, at time <span class="math inline">\(t\)</span> we receive a vector of observations <span class="math inline">\(\mathbf{a}_t\)</span> and an observation of our target variable <span class="math inline">\(b_t\)</span>.</p>
<p>The full set of all observations and target variable data that we have received up to time <span class="math inline">\(t\)</span> is contained in the following matrix and vector:</p>
<p><span class="math display">\[
A_{(t)} = \begin{bmatrix} \cdots\, \mathbf{a}_1^T\, \cdots \\
\cdots\, \mathbf{a}_2^T\, \cdots \\ \vdots \\ \cdots\, \mathbf{a}_t^T\, \cdots \end{bmatrix},\quad
\mathbf{b}_{(t)} = \begin{bmatrix} b_1 \\ b_2 \\ \vdots \\ b_t \end{bmatrix}
\]</span></p>
<p>which says that row <span class="math inline">\(j\)</span> of the matrix <span class="math inline">\(A_{(t)}\)</span> is the <span class="math inline">\(j\)</span>th observation <span class="math inline">\(\mathbf{a}_j^T\)</span>, and the <span class="math inline">\(j\)</span>th entry of <span class="math inline">\(\mathbf{b}_{(t)}\)</span> is <span class="math inline">\(b_j\)</span>.</p>
<p>Here we assume that the vectors <span class="math inline">\(\mathbf{a}\)</span> each contain <span class="math inline">\(n\)</span> observations, so that <span class="math inline">\(A_{(t)}\)</span> is a <span class="math inline">\(t\times n\)</span> matrix and the vector <span class="math inline">\(\mathbf{b}_{(t)}\)</span> is a <span class="math inline">\(t\)</span>-vector.</p>
<p>As long as <span class="math inline">\(t&gt;n\)</span>, i.e.&nbsp;the number of time observations is greater than the number of features/data points in each observation, we can fit a linear model predicting the target as a function of the features <span class="math inline">\(\mathbf{a}\)</span> by solving the following system of equations:</p>
<p><span class="math display">\[
(A^T_{(t)}A_{(t)})\mathbf{x}_{(t)} = A_{(t)}^T\mathbf{b}_{(t)}
\]</span></p>
<p>As the length of the time series increases, the computational difficulty of solving this problem also increases. However, it is possible to re-use work done on the previous time step to avoid solving the full system at each step.</p>
<p>This algorithm is based on the fact that the <em>Gram Matrix</em> <span class="math inline">\(A^T_{(t+1)}A_{(t+1)}\)</span> can be calculated from the Gram matrix <span class="math inline">\(A^T_{(t)}A_{(t)}\)</span> from the previous time step. <span class="math display">\[
A^T_{(t+1)}A_{(t+1)} = A^T_{(t)}A_{(t)} + \mathbf{a}_{t+1}\mathbf{a}_{t+1}^T
\]</span> Similarly, the product <span class="math inline">\(A^T_{(t+1)} \mathbf{b}_{(t+1)}\)</span> can also be updated from the value on the previous time step: <span class="math display">\[
A^T_{(t+1)}\mathbf{b}_{(t+1)} = A^T_{(t)}\mathbf{b}_{(t)} + b_{t+1}\mathbf{a}_{t+1}
\]</span></p>
<p>We can write an efficient algorithm to compute the updated least squares solution as follows:</p>
<ul>
<li><p>Step 1: Pick an initial time <span class="math inline">\(t\)</span> such that <span class="math inline">\(A_{t}\)</span> is square or tall so that the least squares problem can be solved (i.e.&nbsp;wait for enough data to have built up before your start) and then calculate the Gram matrix and the product <span class="math inline">\(A^T_{t} \mathbf{b}_t\)</span> <span class="math display">\[
G_{(t)} = A^T_{(t)}A_{(t)}, \quad \mathbf{h}_{(t)} = A^T_{t}\mathbf{b}_t
\]</span></p></li>
<li><p>Step 2: Find the least squares solution at time <span class="math inline">\(t\)</span> by solving the linear system: <span class="math display">\[
G_{(t)}\mathbf{x}_{(t)} = \mathbf{h}_{(t)}
\]</span></p></li>
<li><p>Step 3: When the next data points <span class="math inline">\(\mathbf{a}_{t+1}\)</span> and <span class="math inline">\(b_{t+1}\)</span>, update <span class="math inline">\(G_{(t+1)}\)</span> and <span class="math inline">\(\mathbf{h}_{(t+1)}\)</span>:</p></li>
</ul>
<p><span class="math display">\[ G_{(t+1)} = G_{(t)} + \mathbf{a}_{t+1}\mathbf{a}^T_{t+1},\quad
\mathbf{h}_{(t+1)} = \mathbf{h}_{(t)} + b_{t+1}\mathbf{a}_{t+1}
\]</span> Then you can repeat Step 2 to find <span class="math inline">\(\mathbf{x}_{t+1}\)</span>. This algorithm can be improved upon slightly using the Matrix Inversion Lemma/Woodbury Formula, which could be a topic for a project (see note at the end which mentions Kalman filters).</p>
<ol type="a">
<li>You are going to use this algorithm to make a linear, autoregressive model that predicts total day-ahead citibike trips from the daily high temperature and the number of daily citibike trips taken each of the past 7 days. The data is contained in the file <a href="https://github.com/georgehagstrom/DATA609Spring2025/blob/main/website/assignments/labs/labData/daily_citibike_trips.csv">daily_citibike_trips.csv</a>.</li>
</ol>
<p>Specifically, for each time point <span class="math inline">\(t&gt;7\)</span> , fit the following model as a least squares estimation problem: <span class="math display">\[
N_{trips,\tau} = \sum_{i=1}^7 C_i N_{trips,\tau-i} + C_T T,
\]</span> Here, each <span class="math inline">\(N_{trips,\tau}\)</span> stands for the number of citibike trips on the <span class="math inline">\(t\)</span>th day of the time series, <span class="math inline">\(T\)</span> stands for the forecast high temperature in New York City that day, and the coefficients <span class="math inline">\(C_i\)</span> and <span class="math inline">\(C_T\)</span> are the decision variables.</p>
<p>Find the coefficients <span class="math inline">\(C_{i,t}\)</span> and <span class="math inline">\(C_{T,t}\)</span> that minimize the mean square errors on all the observed citibike trips prior to time <span class="math inline">\(t\)</span>. Use the recursive least squares optimization outlined in the preamble to this problem to calculate the coefficients for each time point, and plot how they and the <span class="math inline">\(R^2\)</span> of the model change over time.</p>
<p>What patterns do you notice in how the regression coefficients and <span class="math inline">\(R^2\)</span> change over time?</p>
<p>Tip: Be very cautious when coding about the dimensionality of matrices and arrays. In python, <code>a @ a.T</code> will be an 8x8 matrix if <code>a.shape = (8,1)</code>. However, by default <code>a.shape = (8,)</code>, indicating that <code>a</code> is not being treated as either a row or column vector. For this problem it is important that the vectors are either row or column vectors, and not arrays without such an orientation. In python, you can use <code>numpy.reshape</code> to adjust.</p>
<p><strong>Solution:</strong></p>
<p><strong>Step 1.</strong> First, for each time t, we are going to create a feature vector <span class="math inline">\(\mathbf{a}_t\)</span> (8 rows, 1 column, each row has info about past 7 days of trips and temperature for day t), a target vector <span class="math inline">\(b_t\)</span> (the number of trips on day t) and coefficient vector <span class="math inline">\(\mathbf{x}_t\)</span> (8 rows, 1 column, each row has a coefficient at time t). The data matrix <span class="math inline">\(A_t\)</span> is a tx8 matrix (since <span class="math inline">\(\mathbf{a}_t\)</span> has 8 features), we should remember that the number of time observations is greater than the number of features/data points in each observation in order to fit a linear model. We start at day 8 as the previous 7 days are used to form <span class="math inline">\(\mathbf{a}_8\)</span>. In Python, we load the dataset and create lag features for the past 7 days:</p>
<p><span class="math display">\[
\mathbf{a}_t = [N_{trips, t-1}, N_{trips, t-2}, \cdots\ , N_{trips, t-7}, T_t]^T, \\\]</span> <span class="math display">\[b_t=N_{trips,t},\]</span> <span class="math display">\[\mathbf{x}_t = [C_{1,t}, C_{2,t},  \cdots,  C_{7,t},  C_{T,t}]^T, \]</span> <span class="math display">\[A_{(t)} = \begin{bmatrix}
\cdots\, \mathbf{a}_8^T\, \cdots \\
\cdots\, \mathbf{a}_9^T\, \cdots \\
\vdots \\
\cdots\, \mathbf{a}_t^T\, \cdots
\end{bmatrix},\quad \]</span> <span class="math display">\[\mathbf{b}_{(t)} = \begin{bmatrix}
N_{trips, 8} \\ N_{trips, 9} \\
\vdots \\
N_{trips, t}
\end{bmatrix}\]</span></p>
<p>Next, we create the Gram matrix <span class="math inline">\(G_t\)</span> and vector <span class="math inline">\(h_t\)</span>: <span class="math display">\[
G_{(t)} = A^T_{(t)}A_{(t)}, \quad \mathbf{h}_{(t)} = A^T_{t}\mathbf{b}_t.
\]</span></p>
<p><strong>Step 2.</strong> Find the least squares solution at time <span class="math inline">\(t\)</span> by solving the linear system: <span class="math display">\[
G_{(t)}\mathbf{x}_{(t)} = \mathbf{h}_{(t)}
\]</span></p>
<p><strong>Step 3.</strong> We apply reccursive updated to the Gram matrix <span class="math inline">\(G_t\)</span> and vector <span class="math inline">\(h_t\)</span> and solve the updated system:</p>
<p><span class="math display">\[ G_{(t+1)} = G_{(t)} + \mathbf{a}_{t+1}\mathbf{a}^T_{t+1},\quad \]</span> <span class="math display">\[\mathbf{h}_{(t+1)} = \mathbf{h}_{(t)} + b_{t+1}\mathbf{a}_{t+1}, \]</span> <span class="math display">\[G_{(t+1)}\mathbf{x}_{(t+1)} = \mathbf{h}_{(t+1)}.\]</span></p>
<p>In Python, we update for each new data point <span class="math inline">\(G_{(t+1)}, \mathbf{h}_{(t+1)}\)</span>, and solve for updated coefficients <span class="math inline">\(\mathbf{x}_{(t+1)}\)</span>. After, we store coefficients and compute <span class="math inline">\(R^2\)</span> to track model performance.</p>
<p>The strongest weight is on <span class="math inline">\(C_T\)</span>=68.65, temperature has a large positive impact on trip counts. The previous day’s trip count <span class="math inline">\(C_1\)</span>=0.45 is the most influential past trip variable as earlier days have decreasing weight, older data becomes less relevant for prediction.</p>
<p><strong>Step 4.</strong> Plot coefficient trajectories over time to observe how they stabilize, and <span class="math inline">\(R^2\)</span> over time to evaluate model accuracy.</p>
<p>Initially, there are fluctuations in coefficient trajectories as the model adapts to new data, but the coefficients stabilize as more data is incorporated. For the second plot, <span class="math inline">\(R^2\)</span> is initially volatile due to limited data. As more observations are incorporated, <span class="math inline">\(R^2\)</span> improves and stabilizes around 0.84, indicating a good fit.</p>
<div id="05688463" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Import libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">#Load dataset from Github</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">'https://media.githubusercontent.com/media/georgehagstrom/DATA609Spring2025/refs/heads/main/website/assignments/labs/labData/daily_citibike_trips.csv'</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>data.head(), data.describe(), data.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 3949 entries, 0 to 3948
Data columns (total 3 columns):
 #   Column       Non-Null Count  Dtype 
---  ------       --------------  ----- 
 0   date         3949 non-null   object
 1   daily_trips  3949 non-null   int64 
 2   TMAX         3949 non-null   int64 
dtypes: int64(2), object(1)
memory usage: 92.7+ KB</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>(         date  daily_trips  TMAX
 0  2013-05-31          362    90
 1  2013-06-01         8959    90
 2  2013-06-02        15467    88
 3  2013-06-03         7700    78
 4  2013-06-04        15849    75,
          daily_trips         TMAX
 count    3949.000000  3949.000000
 mean    53911.858698    63.637377
 std     33089.106922    17.890984
 min       249.000000    13.000000
 25%     29361.000000    49.000000
 50%     46198.000000    65.000000
 75%     73102.000000    79.000000
 max    161586.000000    98.000000,
 None)</code></pre>
</div>
</div>
<div id="9cc11225" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Step 1</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>bike_df <span class="op">=</span> data.copy()</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Number of features, 7 previous days and temperature</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>n_features <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">#Number of past days to consider</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>start_day <span class="op">=</span> n_features</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">#Data for the previous 7 days</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, start_day):</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    bike_df[<span class="ss">f'lag_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>] <span class="op">=</span> bike_df[<span class="st">'daily_trips'</span>].shift(i)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co">#If any NAs</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>bike_df <span class="op">=</span> bike_df.dropna().reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co">#8 features for a</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> [<span class="ss">f'lag_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, start_day)] <span class="op">+</span> [<span class="st">'TMAX'</span>]</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> bike_df[features].values</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> bike_df[<span class="st">'daily_trips'</span>].values.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="co">#Start values</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>start_size <span class="op">=</span> n_features</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>start_A <span class="op">=</span> X[:start_size, :]</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>start_b <span class="op">=</span> y[:start_size]</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Gram matrix, h vector</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> start_A.T <span class="op">@</span> start_A</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> start_A.T <span class="op">@</span> start_b</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="co">#Step 2</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="co">#Solution of initial least squares problem</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linalg.solve(G, h)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="co">#Step 3</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="co">#Keep regression coefficients</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>coeff_info <span class="op">=</span> [x.flatten()]</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>r2_info <span class="op">=</span> []</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Online Recursive Update</span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(start_size, <span class="bu">len</span>(y)):</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>    a_t <span class="op">=</span> X[t, :].reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>    b_t <span class="op">=</span> y[t, <span class="dv">0</span>]</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Update Gram matrix and h vector</span></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>    G <span class="op">+=</span> a_t <span class="op">@</span> a_t.T</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>    h <span class="op">+=</span> b_t <span class="op">*</span> a_t</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Solve updated system</span></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.linalg.solve(G, h)</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Keep and compute R^2</span></span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>    coeff_info.append(x.flatten())</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>    coeff_info_arr <span class="op">=</span> np.array(coeff_info)</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> X[:t<span class="op">+</span><span class="dv">1</span>, :] <span class="op">@</span> x</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>    ss_total <span class="op">=</span> np.<span class="bu">sum</span>((y[:t<span class="op">+</span><span class="dv">1</span>] <span class="op">-</span> np.mean(y[:t<span class="op">+</span><span class="dv">1</span>])) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>    ss_residual <span class="op">=</span> np.<span class="bu">sum</span>((y[:t<span class="op">+</span><span class="dv">1</span>] <span class="op">-</span> y_pred) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>    r2 <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> (ss_residual <span class="op">/</span> ss_total)</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>    r2_info.append(r2)</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>    r2_info_arr <span class="op">=</span> np.array(r2_info).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="e7fbac5e" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The coefficients C_{i,t} and C_{T,t} that minimize the mean square errors on all the observed citibike trips prior to time t: "</span>, x)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Step 4, plot coeff and r^2</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_features):</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    plt.plot(coeff_info_arr[:, i],label<span class="op">=</span><span class="ss">f'C_</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">if</span> i <span class="op">&lt;</span><span class="dv">7</span> <span class="cf">else</span> <span class="st">'C_T'</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time, days'</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Coefficient Value'</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Coefficients Over Time'</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>plt.plot(r2_info_arr)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time, days'</span>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'R²'</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'R² Over Time'</span>)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="co">#Final temperature coefficient and R^2</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>final_temp_coeff <span class="op">=</span> x[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>]</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>final_r2 <span class="op">=</span> r2_info_arr[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>]</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Final temperature coefficient:"</span>,final_temp_coeff)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Final R²:"</span>, final_r2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The coefficients C_{i,t} and C_{T,t} that minimize the mean square errors on all the observed citibike trips prior to time t:  [[4.52631814e-01]
 [2.49456896e-02]
 [5.73475787e-02]
 [4.94046916e-02]
 [5.95294284e-02]
 [1.03694620e-01]
 [1.81216683e-01]
 [6.86537452e+01]]
Final temperature coefficient: 68.65374516087343
Final R²: 0.8442976618813519</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Applications_of_Least_Squares_files/figure-html/cell-4-output-2.png" width="827" height="671" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\daria\AppData\Local\Temp\ipykernel_23344\3462983360.py:18: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  plt.legend()</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Applications_of_Least_Squares_files/figure-html/cell-4-output-4.png" width="812" height="671" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ol start="2" type="a">
<li>We have included temperature as a variable because it probably influences the decision to ride a citibike. However, the relationship could be nonlinear, as both extreme high and low temperatures make bike riding less comfortable. With this idea in mind, create a new feature by choosing a nonlinear function of the temperature <span class="math inline">\(T\)</span> that represents the potential for both high and low values of <span class="math inline">\(T\)</span> to the same impact on predicted ridership. Use least squares optimization to fit an autoregressive time series model, replacing <span class="math inline">\(T\)</span> with the value of your new feature <span class="math inline">\(f(T)\)</span> in the time series. How does the temperature dependence coefficient differ between this model and the one you fit in (a)? Does the accuracy of the model improve or get worse using the new feature?</li>
</ol>
<p>We can implement new feature via comparison with some base temperature <span class="math inline">\(T_0\)</span> (for example, 65 as the median temperature) and make it non-linear by using power of 2: <span class="math inline">\(f(T) = (T-T_0)^2.\)</span></p>
<p>We are going to use the same recursive least squares approach as in part (a), but replace <span class="math inline">\(T\)</span> with <span class="math inline">\(f(T)\)</span>. In part (a), the temperature coefficient was 68.65 (a strong positive correlation between temperature and daily trips). In part (b), the new temperature coefficient after the nonlinear transformation <span class="math inline">\(C_T=-1.74\)</span>, the extreme temperatures or a deviation from the median reduce bike usage. In part (a) and (b), the final <span class="math inline">\(R^2\)</span> was the same 0.8443, using the transformed feature did not improve the model’s ability to explain variance in the data, the linear model already captured most of the variability. Further, we could try other nonlinear transformations (exponential, sigmoid, etc) to see how they affect model’s performance.</p>
<div id="7c584d77" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Implement non-linear temperature</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>T_o <span class="op">=</span> bike_df[<span class="st">'TMAX'</span>].median()</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>bike_df[<span class="st">'T_transformed'</span>] <span class="op">=</span> (bike_df[<span class="st">'TMAX'</span>] <span class="op">-</span> T_o) <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">#8 features for a with new T</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>features_new <span class="op">=</span> [<span class="ss">f'lag_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, start_day)] <span class="op">+</span> [<span class="st">'T_transformed'</span>]</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>X_new <span class="op">=</span> bike_df[features_new].values</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>y_new <span class="op">=</span> bike_df[<span class="st">'daily_trips'</span>].values.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co">#Start values</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>start_size <span class="op">=</span> n_features</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>start_A <span class="op">=</span> X_new[:start_size, :]</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>start_b <span class="op">=</span> y_new[:start_size]</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Gram matrix, h vector</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>G_new <span class="op">=</span> start_A.T <span class="op">@</span> start_A</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>h_new <span class="op">=</span> start_A.T <span class="op">@</span> start_b</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="co">#Step 2</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="co">#Solution of initial least squares problem</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>x_new <span class="op">=</span> np.linalg.solve(G_new, h_new)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a><span class="co">#Step 3</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="co">#Keep regression coefficients</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>coeff_info_new <span class="op">=</span> [x_new.flatten()]</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>r2_info_new <span class="op">=</span> []</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Online Recursive Update</span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(start_size, <span class="bu">len</span>(y_new)):</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>    a_t <span class="op">=</span> X_new[t, :].reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>    b_t <span class="op">=</span> y_new[t, <span class="dv">0</span>]</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Update Gram matrix and h vector</span></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>    G_new <span class="op">+=</span> a_t <span class="op">@</span> a_t.T</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>    h_new <span class="op">+=</span> b_t <span class="op">*</span> a_t</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Solve updated system</span></span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>    x_new <span class="op">=</span> np.linalg.solve(G_new, h_new)</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Keep and compute R^2</span></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>    coeff_info_new.append(x_new.flatten())</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>    y_pred_new <span class="op">=</span> X_new[:t<span class="op">+</span><span class="dv">1</span>, :] <span class="op">@</span> x_new</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>    ss_total <span class="op">=</span> np.<span class="bu">sum</span>((y_new[:t<span class="op">+</span><span class="dv">1</span>] <span class="op">-</span> np.mean(y_new[:t<span class="op">+</span><span class="dv">1</span>])) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>    ss_residual <span class="op">=</span> np.<span class="bu">sum</span>((y_new[:t<span class="op">+</span><span class="dv">1</span>] <span class="op">-</span> y_pred_new) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>    r2_new <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> (ss_residual <span class="op">/</span> ss_total)</span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>    r2_info_new.append(r2)</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>coeff_info_arr_new <span class="op">=</span> np.array(coeff_info_new)</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>r2_info_arr_new <span class="op">=</span> np.array(r2_info_new).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="df97f84c" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The coefficients C_{i,t} and C_{T,t} that minimize the mean square errors on all the observed citibike trips prior to time t: "</span>, x_new)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co">#Step 4, plot coeff and r^2</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_features):</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    plt.plot(coeff_info_arr_new[:, i],label<span class="op">=</span><span class="ss">f'C_</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">if</span> i <span class="op">&lt;</span><span class="dv">7</span> <span class="cf">else</span> <span class="st">'C_T_new'</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time, days'</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Coefficient Value'</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Coefficients Over Time (Nonlinear Temperature)'</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>plt.plot(r2_info_arr_new)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time, days'</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'R²'</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'R² Over Time (Nonlinear Temperature)'</span>)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="co">#Final temperature coefficient and R^2</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>final_temp_coeff_new <span class="op">=</span> x_new[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>]</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>final_r2_new <span class="op">=</span> r2_info_arr_new[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>]</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Final temperature coefficient (nonlinear model):"</span>,final_temp_coeff_new)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Final R² (nonlinear model):"</span>, final_r2_new)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The coefficients C_{i,t} and C_{T,t} that minimize the mean square errors on all the observed citibike trips prior to time t:  [[ 0.4719551 ]
 [ 0.03495606]
 [ 0.06626496]
 [ 0.05770381]
 [ 0.06877473]
 [ 0.11162964]
 [ 0.18942578]
 [-1.73857289]]
Final temperature coefficient (nonlinear model): -1.7385728856759814
Final R² (nonlinear model): 0.8442976618813519</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Applications_of_Least_Squares_files/figure-html/cell-6-output-2.png" width="819" height="671" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\daria\AppData\Local\Temp\ipykernel_23344\1709111856.py:17: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  plt.legend()</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Applications_of_Least_Squares_files/figure-html/cell-6-output-4.png" width="821" height="671" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="problem-2-weighted-least-squares" class="level2">
<h2 class="anchored" data-anchor-id="problem-2-weighted-least-squares">Problem 2: Weighted Least Squares</h2>
<p>The file <a href="https://github.com/georgehagstrom/DATA609Spring2025/blob/main/website/assignments/labs/labData/social_mobility.csv">social-mobility.csv</a> contains data on the fraction of individuals born in the years 1980-1982 to parents in the bottom 20% of the income distribution who reach the top 20% of the income distribution by the time they turn 30 in a large number of municipalities throughout the United States. The dataset also contains additional variables that describe other socio-economic differences between the cities in the dataset.</p>
<ol type="a">
<li>Make a scatter-plot of mobility versus population (use a log-scale for population). What do you notice about the variance of social mobility as a function of population? This is a common feature of nearly every dataset containing geographic regions with widely different populations.</li>
</ol>
<p><strong>Solution:</strong> After constructing the Mobility vs.&nbsp;Population plot (log scale), we noticed that the variance of social mobility decreases as population increases: data points are more dispersed on the left, between 0.025 and 0.35 (where the population is lower), and more tightly clustered on the right, approximately between 0.025 and 0.125 (where the population is higher).</p>
<p>From this plot, we might think that social mobility is lower in larger cities. However, outliers exist, as some small cities exhibit low mobility, while some large cities have unexpectedly high mobility.</p>
<div id="d29f1796" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Load dataset from Github</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">'https://media.githubusercontent.com/media/georgehagstrom/DATA609Spring2025/refs/heads/main/website/assignments/labs/labData/social_mobility.csv'</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>data.head(), data.describe(), data.info()</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co">#Scatter plot mobility vs population</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>mobility_df <span class="op">=</span> data.copy()</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>plt.scatter(mobility_df[<span class="st">'Population'</span>], mobility_df[<span class="st">'Mobility'</span>])</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>plt.xscale(<span class="st">'log'</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Population, log scale'</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Social Mobility'</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Social Mobility vs. Population'</span>)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 711 entries, 0 to 710
Data columns (total 7 columns):
 #   Column                 Non-Null Count  Dtype  
---  ------                 --------------  -----  
 0   ID                     711 non-null    int64  
 1   Name                   711 non-null    object 
 2   Mobility               699 non-null    float64
 3   State                  711 non-null    object 
 4   Population             711 non-null    int64  
 5   Student_teacher_ratio  711 non-null    float64
 6   Commute                711 non-null    float64
dtypes: float64(3), int64(2), object(2)
memory usage: 39.0+ KB</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Applications_of_Least_Squares_files/figure-html/cell-7-output-2.png" width="812" height="672" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ol start="2" type="a">
<li>Assume that the number of children born in families making below the 20th percentile of the income distribution in each city is linearly proportional to the city population. Write down a formula for how the variance of each measurement of the social mobility should depend on the measured social mobility and the population. Hint: start with either the formula for the variance of binomial counts or look up the variance of a proportion derived from a binomial distribution. Don’t worry about constant factors when deriving this formula.</li>
</ol>
<p><strong>Solution:</strong> We assume a binomial distribution, assuming that the number of children born to families in the bottom 20% of the income distribution in each city is linearly proportional to the city population.</p>
<p>Let <span class="math inline">\(N\)</span> be the city population, <span class="math inline">\(k*N\)</span> be the number of children born in the bottom 20% of the income distribution (where k is a constant of proportionality), <span class="math inline">\(p\)</span> be the measured social mobility, which represents the probability of an individual moving from the bottom 20% to the top 20%. Since the number of successful transitions follows a binomial distribution:</p>
<p><span class="math display">\[X \propto \text{Binomial}(kN,p)\]</span></p>
<p>The variance of a binomial random variable is <span class="math display">\[Var(X) = kNp(1 - p)\]</span>.</p>
<p>Since social mobility is measured as a proportion:</p>
<p><span class="math display">\[p = \frac{X}{kN}, \]</span> <span class="math display">\[Var(p) = Var(\frac{X}{k N}) = \frac{1}{(kN)^2} \cdot \text{Var}(\text{X}), \]</span> <span class="math display">\[Var(p) = \frac{1}{(k \cdot N)^2} \cdot (k \cdot N \cdot p \cdot (1 - p)) = \frac{p \cdot (1 - p)}{k \cdot N}.\]</span></p>
<p>The variance of social mobility is proportional to the following expression, as k is an unknown constant: <span class="math display">\[\text{Variance} \propto \frac{\text{Mobility} \cdot (1 - \text{Mobility})}{\text{Population}}.\]</span></p>
<div id="8ea91398" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">#variance estimate</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>mobility_df[<span class="st">'Variance'</span>] <span class="op">=</span> (mobility_df[<span class="st">'Mobility'</span>] <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> mobility_df[<span class="st">'Mobility'</span>])) <span class="op">/</span> mobility_df[<span class="st">'Population'</span>]</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co">#weights as the inverse of variance</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>mobility_df[<span class="st">'Weight'</span>] <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> mobility_df[<span class="st">'Variance'</span>]</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">#remove invalid entries</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>mobility_df <span class="op">=</span> mobility_df.dropna(subset<span class="op">=</span>[<span class="st">'Variance'</span>])  <span class="co"># Remove NaN values</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>mobility_df <span class="op">=</span> mobility_df[mobility_df[<span class="st">'Variance'</span>] <span class="op">&gt;</span> <span class="dv">0</span>]  <span class="co"># Remove zero variance cases</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>mobility_df[[<span class="st">'Mobility'</span>, <span class="st">'Population'</span>, <span class="st">'Variance'</span>, <span class="st">'Weight'</span>]].head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Mobility</th>
<th data-quarto-table-cell-role="th">Population</th>
<th data-quarto-table-cell-role="th">Variance</th>
<th data-quarto-table-cell-role="th">Weight</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.072635</td>
<td>66708</td>
<td>1.009763e-06</td>
<td>9.903313e+05</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.044801</td>
<td>493180</td>
<td>8.677092e-08</td>
<td>1.152460e+07</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.047397</td>
<td>1055133</td>
<td>4.279126e-08</td>
<td>2.336926e+07</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.051663</td>
<td>90016</td>
<td>5.442816e-07</td>
<td>1.837284e+06</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.079570</td>
<td>64676</td>
<td>1.132391e-06</td>
<td>8.830872e+05</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<ol start="3" type="a">
<li><p>Use weighted least squares to calculate an estimate of how social mobility depends on commute time and student-teacher ratio, using weights calculated based on the variance estimate derived in (b). Compare the coefficients to those derived from ordinary least squares with no weights.</p>
<p><strong>Solution:</strong></p>
<p>For OLS, the coefficient for commute time is 0.2118 (highly significant, p&lt;0.001),</p>
<p>for student-teacher ratio is -0.0019 (significant, p=0.014),</p>
<p>intercept is 0.036 (significant,p=0.027),</p>
<p><span class="math inline">\(R^2\)</span> is 0.356 (moderate explanatory power).</p>
<p>For WLS: The coefficient for commute time is 0.0624 (highly significant, p&lt;0.001),</p>
<p>for student-teacher ratio is 0.0031 (significant, p&lt;0.001, opposite sign from OLS),</p>
<p>intercept is −0.0025 (not significant, p=0.776),</p>
<p><span class="math inline">\(R^2\)</span> is 0.095 (much lower than OLS, WLS models less variance).</p>
<p>The OLS model estimates much stronger effects for commute time and a slightly negative effect for student-teacher ratio. OLS overestimates commute time’s importance. The WLS model, which accounts for variance heterogeneity, shows smaller coefficients. Commute time still positively influences mobility but with a lower effect. Student-teacher ratio changes sign to a small positive value, indicating that when correcting for variance, its effect might be different from what OLS suggests. Weighting leads to a large drop in <span class="math inline">\(R^2\)</span> (from 0.356 to 0.095).</p>
<p>As a result, OLS may overstate effects due to uncorrected variance differences across cities. WLS gives a more reliable estimation by correcting for population-dependent variance, but the predictive power drops. Commute time and student-teacher ratio still significantly affect social mobility, but their impact is more nuanced when properly weighted.</p></li>
</ol>
<div id="8a2cd341" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Independent variables, intercept</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> mobility_df[[<span class="st">'Commute'</span>, <span class="st">'Student_teacher_ratio'</span>]]</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(X)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co">#Dependent variable</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> mobility_df[<span class="st">'Mobility'</span>]</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co">#OLS regression</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>ols_model <span class="op">=</span> sm.OLS(y, X).fit()</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co">#WLS regression using computed weights</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>wls_model <span class="op">=</span> sm.WLS(y, X, weights<span class="op">=</span>mobility_df[<span class="st">'Weight'</span>]).fit()</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="co">#Summary of both models</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>ols_summary <span class="op">=</span> ols_model.summary()</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>wls_summary <span class="op">=</span> wls_model.summary()</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>ols_summary, wls_summary</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>(&lt;class 'statsmodels.iolib.summary.Summary'&gt;
 """
                             OLS Regression Results                            
 ==============================================================================
 Dep. Variable:               Mobility   R-squared:                       0.356
 Model:                            OLS   Adj. R-squared:                  0.354
 Method:                 Least Squares   F-statistic:                     192.6
 Date:                Wed, 26 Feb 2025   Prob (F-statistic):           2.72e-67
 Time:                        14:52:36   Log-Likelihood:                 1213.6
 No. Observations:                 699   AIC:                            -2421.
 Df Residuals:                     696   BIC:                            -2408.
 Df Model:                           2                                         
 Covariance Type:            nonrobust                                         
 =========================================================================================
                             coef    std err          t      P&gt;|t|      [0.025      0.975]
 -----------------------------------------------------------------------------------------
 const                     0.0360      0.016      2.214      0.027       0.004       0.068
 Commute                   0.2118      0.013     16.349      0.000       0.186       0.237
 Student_teacher_ratio    -0.0019      0.001     -2.471      0.014      -0.003      -0.000
 ==============================================================================
 Omnibus:                      250.548   Durbin-Watson:                   1.366
 Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1772.747
 Skew:                           1.424   Prob(JB):                         0.00
 Kurtosis:                      10.264   Cond. No.                         201.
 ==============================================================================
 
 Notes:
 [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
 """,
 &lt;class 'statsmodels.iolib.summary.Summary'&gt;
 """
                             WLS Regression Results                            
 ==============================================================================
 Dep. Variable:               Mobility   R-squared:                       0.095
 Model:                            WLS   Adj. R-squared:                  0.093
 Method:                 Least Squares   F-statistic:                     36.64
 Date:                Wed, 26 Feb 2025   Prob (F-statistic):           7.41e-16
 Time:                        14:52:36   Log-Likelihood:                 1098.8
 No. Observations:                 699   AIC:                            -2192.
 Df Residuals:                     696   BIC:                            -2178.
 Df Model:                           2                                         
 Covariance Type:            nonrobust                                         
 =========================================================================================
                             coef    std err          t      P&gt;|t|      [0.025      0.975]
 -----------------------------------------------------------------------------------------
 const                    -0.0025      0.009     -0.285      0.776      -0.020       0.015
 Commute                   0.0624      0.011      5.680      0.000       0.041       0.084
 Student_teacher_ratio     0.0031      0.000      7.904      0.000       0.002       0.004
 ==============================================================================
 Omnibus:                      159.098   Durbin-Watson:                   0.923
 Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2562.771
 Skew:                           0.537   Prob(JB):                         0.00
 Kurtosis:                      12.319   Cond. No.                         262.
 ==============================================================================
 
 Notes:
 [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
 """)</code></pre>
</div>
</div>
</section>
<section id="problem-3-markowitz-portfolio-optimization" class="level2">
<h2 class="anchored" data-anchor-id="problem-3-markowitz-portfolio-optimization">Problem 3: Markowitz Portfolio Optimization</h2>
<p>In this problem you will use <em>Markowitz Portfolio Optimization</em> to construct a set of portfolios that aim to achieve target expected rates of return while minimizing risk. The file <a href="https://github.com/georgehagstrom/DATA609Spring2025/blob/main/website/assignments/labs/labData/stock_returns.csv">stock_returns.csv</a> contains information on daily asset returns from 2020-2024 for a group of assets, consisting mostly of large-cap stocks but also a handful of exchange traded funds that correspond to US Treasury Bonds and Notes with varying maturities.</p>
<p>You will divide the data into two time periods, a training period (2020-2022) and a testing period (2022-2024). The data in the <code>stock_returns.csv</code> is stored in a long format, with the following variables:</p>
<ol type="1">
<li><code>Company</code> - The ticker symbol that identifies the stock</li>
<li><code>date</code> - The date to which the data corresponds</li>
<li><code>adjusted</code>- the closing price of the stock, adjusted for special events like dividends and stock splits</li>
<li><code>return</code> - the ratio of the current adjusted close to the adjusted close on the previous trading day</li>
<li><code>log_return</code>- the natural logarithm of the return</li>
</ol>
<!-- -->
<ol type="a">
<li>Construct a vector (we call it <span class="math inline">\(\mu\)</span>) containing the annualized rate of return over the training period (for the <span class="math inline">\(i\)</span>th stock, you can use the formula: <span class="math inline">\(\mu_i = \exp\left(0.5\sum_{t} \mathrm{log\_return}_i(t)\right)\)</span>), or the square root of the total return over the first two years of data, and daily return covariance <span class="math inline">\(\Gamma\)</span>.</li>
</ol>
<p><strong>Hint</strong>: Possible workflow if working in python: convert your data to a wide format using <code>pandas</code>, extract the values into a <code>numpy ndarray</code>, and then use the function <code>np.cov</code>.</p>
<p>Then solve the following constrained least squares problem to calculate optimal portfolios achieving a fixed rate of return with minimum variance:</p>
<p><span class="math display">\[
\begin{aligned}
    \min_{w} \mathbf{x}^T\Gamma \mathbf{x}, \\
    \mathbf{w}^T\mathbf{\mu} = r, \\
    \sum_{i} w_i = 1
\end{aligned}
\]</span> Here <span class="math inline">\(\mathbf{w}\)</span> is a vector containing the investment allocations into different assets, and <span class="math inline">\(r\)</span> is the target rate of return.</p>
<p>Calculate optimal portfolios based on the 2020-2022 data for <span class="math inline">\(r=1.05\)</span>, <span class="math inline">\(r=1.10\)</span>, and <span class="math inline">\(r=1.20\)</span>.</p>
<p><strong>Solution:</strong></p>
<p>First, we load the dataset, convert it into a DataFrame, and split the data into a training period (2020–2022) and a testing period (2023–2024). We use the training data to estimate <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Gamma\)</span>, aand the testing data for validation. After splitting the data, we pivot training data to wide format where each column corresponds to one asset’s daily log returns, and each row corresponds to a trading day.</p>
<p>Next, we construct a vector <span class="math inline">\(\mu\)</span> a one-dimensional array whose length is equal to the number of assets, containing the annualized rate of return over the training period. In Python, we also extract values into numpy ndarray after using the formula:</p>
<p><span class="math display">\[\mu_i = \exp\left(0.5\sum_{t} \mathrm{log\_return}_i(t)\right).\]</span></p>
<p>We compute the covariance matrix <span class="math inline">\(\Gamma\)</span> using daily log returns. In Python, we apply np.cov() to the values in the wide-format training dataset. The resulting matrix has dimensions equal to the number of assets x the number of assets:</p>
<p><span class="math display">\[\Gamma = \mathrm{cov}(\mathrm{log\_return}).\]</span></p>
<p>As the last step, we solve the optimization proble using the formulas from the problem statement. In Python, we can use scipy.optimize() with the Sequential Least Squares Programming (SLSQP, commonly used for solving constrained optimization problems) method to solve this problem. The portfolio variance is defined by <span class="math inline">\(\mathbf{w}^T\Gamma \mathbf{w}\)</span>. The constraint <span class="math inline">\(\mathbf{w}^T\mathbf{\mu} = r\)</span> iensures that the portfolio achieves the target return, while <span class="math inline">\(\sum_{i} w_i = 1\)</span> enforces a fully invested portfolio by requiring that all weights sum to 1. In most portfolio optimization problems, weight bounds are enforced, typically restricting each weight to be between 0 and 1 (i.e., no short-selling). However, since the problem statement does not specify such constraints, we allow short selling in this implementation. The starting point of the optimization is equal weights (1/len(<span class="math inline">\(\mathbf{\mu}\)</span>)). We then call the portfolio_optimize function for three target returns: 1.05, 1.10, and 1.20. Each call returns a weight vector <span class="math inline">\(\mathbf{w}\)</span>. The results are printed below. We verify that the sum of weights for each target return is equal to 1 and that the portfolio’s expected annualized return closely matches the specified target. Some weights may be negative (indicating short positions) because we have not enforced non-negativity constraints.</p>
<div id="b6d3c1aa" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Load dataset from Github</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">'https://media.githubusercontent.com/media/georgehagstrom/DATA609Spring2025/refs/heads/main/website/assignments/labs/labData/stock_returns.csv'</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Convert to df</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'date'</span>] <span class="op">=</span> pd.to_datetime(data[<span class="st">'date'</span>])</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co">#Split to train and test</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>stock_df <span class="op">=</span> data.copy()</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> stock_df[(stock_df[<span class="st">'date'</span>] <span class="op">&gt;=</span> <span class="st">'2020-01-01'</span>) <span class="op">&amp;</span> (stock_df[<span class="st">'date'</span>] <span class="op">&lt;=</span> <span class="st">'2022-12-31'</span>)]</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> stock_df[(stock_df[<span class="st">'date'</span>] <span class="op">&gt;=</span> <span class="st">'2023-01-01'</span>) <span class="op">&amp;</span> (stock_df[<span class="st">'date'</span>] <span class="op">&lt;=</span> <span class="st">'2024-12-31'</span>)]</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>data.head(), data.describe(), data.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 592047 entries, 0 to 592046
Data columns (total 5 columns):
 #   Column      Non-Null Count   Dtype         
---  ------      --------------   -----         
 0   Company     592047 non-null  object        
 1   date        592047 non-null  datetime64[ns]
 2   adjusted    592047 non-null  float64       
 3   return      592047 non-null  float64       
 4   log_return  592047 non-null  float64       
dtypes: datetime64[ns](1), float64(3), object(1)
memory usage: 22.6+ MB</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>(  Company       date   adjusted    return  log_return
 0    AAPL 2020-01-02  72.796028  1.022817    0.022560
 1    AAPL 2020-01-03  72.088295  0.990278   -0.009770
 2    AAPL 2020-01-06  72.662704  1.007968    0.007937
 3    AAPL 2020-01-07  72.320969  0.995297   -0.004714
 4    AAPL 2020-01-08  73.484352  1.016086    0.015958,
                                 date       adjusted         return  \
 count                         592047  592047.000000  592047.000000   
 mean   2022-06-30 22:13:27.637231360     155.893055       1.000691   
 min              2020-01-02 00:00:00       0.979024       0.470926   
 25%              2021-04-01 00:00:00      41.990664       0.990436   
 50%              2022-06-30 00:00:00      85.252342       1.000618   
 75%              2023-09-29 00:00:00     171.392616       1.010869   
 max              2024-12-30 00:00:00    9924.400391       1.665000   
 std                              NaN     338.845444       0.023503   
 
           log_return  
 count  592047.000000  
 mean        0.000414  
 min        -0.753054  
 25%        -0.009610  
 50%         0.000617  
 75%         0.010810  
 max         0.509825  
 std         0.023591  ,
 None)</code></pre>
</div>
</div>
<div id="3c6d0f79" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Pivot to wide format, shape: number of trading days x stocks </span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>train_wide <span class="op">=</span> train_df.pivot(index<span class="op">=</span><span class="st">'date'</span>, columns<span class="op">=</span><span class="st">'Company'</span>, values<span class="op">=</span><span class="st">'log_return'</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>test_wide <span class="op">=</span> test_df.pivot(index<span class="op">=</span><span class="st">'date'</span>, columns<span class="op">=</span><span class="st">'Company'</span>, values<span class="op">=</span><span class="st">'log_return'</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="co">#mu, a vector containing the annualized rate of return over the training period </span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> np.exp(<span class="fl">0.5</span> <span class="op">*</span> train_wide.<span class="bu">sum</span>()) </span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> mu.values</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="co">#Covariance matrix, rowvar=False - columns are variables </span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>Gamma <span class="op">=</span> np.cov(train_wide.values, rowvar<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="bu">isinstance</span>(mu, np.ndarray), <span class="bu">isinstance</span>(Gamma, np.ndarray), <span class="bu">len</span>(mu), <span class="bu">len</span>(Gamma)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>(True, True, 471, 471)</code></pre>
</div>
</div>
<div id="fc458232" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> portfolio_optimize(mu, Gamma, target_return):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Variance</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> portfolio_var(w):</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> w.T <span class="op">@</span> Gamma <span class="op">@</span> w</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Constraints, weights should sum to 1</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    constraints <span class="op">=</span> [</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>        {<span class="st">'type'</span>: <span class="st">'eq'</span>, <span class="st">'fun'</span>: <span class="kw">lambda</span> w: w.T <span class="op">@</span> mu <span class="op">-</span> target_return},</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>        {<span class="st">'type'</span>: <span class="st">'eq'</span>, <span class="st">'fun'</span>: <span class="kw">lambda</span> w: np.<span class="bu">sum</span>(w) <span class="op">-</span> <span class="dv">1</span>}</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Each weight must be between 0 and 1</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    n_companies <span class="op">=</span> <span class="bu">len</span>(mu)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Initial condition</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    initial_cond <span class="op">=</span> np.array([<span class="dv">1</span><span class="op">/</span>n_companies] <span class="op">*</span> n_companies)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    bounds <span class="op">=</span> <span class="bu">tuple</span>((<span class="va">None</span>, <span class="va">None</span>) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_companies))</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">#The optimization problem</span></span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> minimize(portfolio_var, initial_cond, bounds <span class="op">=</span> bounds, method<span class="op">=</span><span class="st">'SLSQP'</span>, constraints<span class="op">=</span>constraints)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result.x</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a><span class="co">#Solve for a target return of 1.05 (5% above baseline)</span></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>target_return <span class="op">=</span> <span class="fl">1.05</span></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>optimal_weights <span class="op">=</span> portfolio_optimize(mu, Gamma, target_return)</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a><span class="co">#Keep data</span></span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>portfolios <span class="op">=</span> {}</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>portfolios[target_return] <span class="op">=</span> optimal_weights</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a><span class="co">#Print results in readable format</span></span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>optimal_weights_rounded <span class="op">=</span> np.<span class="bu">round</span>(optimal_weights, <span class="dv">4</span>)</span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>company_name <span class="op">=</span> train_wide.columns</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>optimal_portfolio_df <span class="op">=</span> pd.DataFrame({<span class="st">'Company'</span>: company_name, <span class="st">'Optimal weight'</span>: optimal_weights_rounded})</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"For a target return of 1.05: "</span>)</span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(optimal_portfolio_df)</span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sum of weights, should be 1:"</span>, np.<span class="bu">sum</span>(optimal_weights))</span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Portfolio expected return:"</span>, optimal_weights.T <span class="op">@</span> mu)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>For a target return of 1.05: 
    Company  Optimal weight
0         A         -0.0000
1      AAPL         -0.0035
2      ABBV          0.0096
3      ABEV          0.0059
4       ABT          0.0007
..      ...             ...
466     YUM          0.0072
467     ZBH          0.0065
468      ZM          0.0267
469      ZS          0.0075
470     ZTS         -0.0003

[471 rows x 2 columns]
Sum of weights, should be 1: 1.0
Portfolio expected return: 1.0500000003312249</code></pre>
</div>
</div>
<div id="42840a21" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Solve for a target return of 1.1 (10% above baseline)</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>target_return <span class="op">=</span> <span class="fl">1.1</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>optimal_weights <span class="op">=</span> portfolio_optimize(mu, Gamma, target_return)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Keep data</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>portfolios[target_return] <span class="op">=</span> optimal_weights</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co">#Print results in readable format</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>optimal_weights_rounded <span class="op">=</span> np.<span class="bu">round</span>(optimal_weights, <span class="dv">4</span>)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>company_name <span class="op">=</span> train_wide.columns</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>optimal_portfolio_df <span class="op">=</span> pd.DataFrame({<span class="st">'Company'</span>: company_name, <span class="st">'Optimal weight'</span>: optimal_weights_rounded})</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"For a target return of 1.1: "</span>)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(optimal_portfolio_df)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sum of weights, should be 1:"</span>, np.<span class="bu">sum</span>(optimal_weights))</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Portfolio expected return:"</span>, optimal_weights.T <span class="op">@</span> mu)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>For a target return of 1.1: 
    Company  Optimal weight
0         A          0.0002
1      AAPL         -0.0030
2      ABBV          0.0108
3      ABEV          0.0054
4       ABT          0.0004
..      ...             ...
466     YUM          0.0075
467     ZBH          0.0060
468      ZM          0.0262
469      ZS          0.0081
470     ZTS         -0.0008

[471 rows x 2 columns]
Sum of weights, should be 1: 1.0000000000000002
Portfolio expected return: 1.100000000144312</code></pre>
</div>
</div>
<div id="1076db61" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Solve for a target return of 1.2 (20% above baseline)</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>target_return <span class="op">=</span> <span class="fl">1.2</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>optimal_weights <span class="op">=</span> portfolio_optimize(mu, Gamma, target_return)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Keep data</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>portfolios[target_return] <span class="op">=</span> optimal_weights</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="co">#Print results in readable format</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>optimal_weights_rounded <span class="op">=</span> np.<span class="bu">round</span>(optimal_weights, <span class="dv">4</span>)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>company_name <span class="op">=</span> train_wide.columns</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>optimal_portfolio_df <span class="op">=</span> pd.DataFrame({<span class="st">'Company'</span>: company_name, <span class="st">'Optimal weight'</span>: optimal_weights_rounded})</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"For a target return of 1.2: "</span>)</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(optimal_portfolio_df)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sum of weights, should be 1:"</span>, np.<span class="bu">sum</span>(optimal_weights))</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Portfolio expected return:"</span>, optimal_weights.T <span class="op">@</span> mu)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>For a target return of 1.2: 
    Company  Optimal weight
0         A          0.0008
1      AAPL         -0.0020
2      ABBV          0.0130
3      ABEV          0.0044
4       ABT         -0.0001
..      ...             ...
466     YUM          0.0080
467     ZBH          0.0052
468      ZM          0.0252
469      ZS          0.0092
470     ZTS         -0.0017

[471 rows x 2 columns]
Sum of weights, should be 1: 1.0
Portfolio expected return: 1.2000000005231843</code></pre>
</div>
</div>
<ol start="2" type="a">
<li>Plot the cumulative value of each portfolio over time, assuming that an initial investment is made at the start of the period and that there is no rebalancing of the portfolio, i.e.&nbsp;<span class="math inline">\(r_{T} = \sum_{i=1}^n w_i\Pi_{t=1}^T r_{it}\)</span>, where <span class="math inline">\(r_{it}\)</span> is the return of asset <span class="math inline">\(i\)</span> on trading day <span class="math inline">\(t\)</span>, (hint: <code>np.cumprod</code> allows you to efficiently calculate this quantity). Make the plot for both the training and test sets of returns.</li>
</ol>
<p>For each of the 3 portfolios also report:</p>
<ul>
<li>The annualized return on the training and test sets;</li>
<li>The risk on the training and test sets, defined as the realized variance of the daily return;</li>
<li>The asset with the maximum allocation weight, and its weight;</li>
<li>The initial leverage, defined as <span class="math inline">\(\sum_{i=1}^n |w_i|\)</span>. This number is always at least one, and it is exactly one only if the portfolio has no short positions.</li>
</ul>
<p>Comment briefly on your observations about the different portfolios and the difference between their training and testing performance.</p>
<p><strong>Solution:</strong></p>
<p>First, we pivot the training data to a wide format, where each column corresponds to one asset’s daily returns (instead of log returns), and each row represents a trading day. This transformation allows us to apply the cumprod() function to compute cumulative returns efficiently. We need to find cumulative value of each portfolio over time, assuming that an initial investment is made at the start of the period and that there is no rebalancing of the portfolio (each asset i grows over time by multiplying its daily returns cumulatively).</p>
<p>We use the cumprod() function in Python to compute the cumulative product of daily returns for each asset. Then, we compute the portfolio’s cumulative value by performing a dot product of these cumulative asset returns with the optimized portfolio weights. The result is a time series of portfolio values over time. For the annualized return, we assume 252 trading days per year based on our data and common convention. The portfolio starts at 1 and ends at final_val over T trading days. The realized variance of the daily return is percentage change (pct_change() in Python) and varince taking after of these daily returns. For the asset with the maximum allocation weight, and its weight, we find the index of the largest weight, and find the sum of absolute weight we found in part a. A leverage above 1 indicates that the portfolio is taking leveraged positions, which may involve short selling or borrowing to invest more than the initial capital. This aligns with our discussion in Part (a), where short selling was allowed in the optimization process.</p>
<p>As a result, we compute the training portfolio value (2020-2022) and metrics, and also the test portfolio value (2023-2024) and metrics, using the same weights. The <span class="math inline">\(r=1.20\)</span> portfolio exhibits higher leverage and/or short positions, leading to higher returns during the training period but also higher volatility. The <span class="math inline">\(r=1.05\)</span> portfolio is comparatively more stable, yielding lower returns with reduced variance. However, when tested on out-of-sample data, all portfolios underperform compared to their training performance, likely due to overfitting or changes in market conditions. The training annualized returns range from about 4.78% to 15.64%. The test annualized returns are lower, the portfolios did not perform as well out of sample. The r=1.20 managed a small positive return in testing. The r=1.05 and r=1.10 portfolios hover slightly above or below the initial value, producing small or even negative annualized returns for the test set. Max‐weight asset is TLT with weight 0.0416. The higher returns in training compared to testing may indicate overfitting or market change over time. The portfolio optimized for r=1.20 took on more aggressive (and presumably leveraged) positions. While it achieved a higher training‐period return, it did not experience a dramatic drop in testing and actually slightly outperformed the lower‐target‐return portfolios in the test period (albeit with some volatility). All portfolios exhibit total leverage greater than 1 (short positions).</p>
<p>The two plots below are for train and test sets for the cumulative value of each portfolio over time (<span class="math inline">\(r=1.05, 1.10, 1.20\)</span>). On the plot for the training set, portfolio’s value evolved in sample, with the higher target return portfolio typically growing faster. On the plot for the test set, we see how the portfolios performed on new data, without re‐optimization or rebalancing. The training period plot shows a strong upward trend for all portfolios, with the <span class="math inline">\(r=1.20\)</span> portfolio experiencing the highest growth. However, in the test period plot, the cumulative portfolio values show much smaller gains, with noticeable fluctuations and occasional declines. This suggests that the optimized portfolios, while effective in-sample, do not generalize well to unseen data. The difference is likely due to the assumption that historical returns and covariance structures remain stable, which may not hold in real-world financial markets.</p>
<div id="5b90be24" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Creating dfs with returns instead of log_returns</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>train_wide_ret <span class="op">=</span> train_df.pivot(index<span class="op">=</span><span class="st">'date'</span>, columns<span class="op">=</span><span class="st">'Company'</span>, values<span class="op">=</span><span class="st">'return'</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>test_wide_ret  <span class="op">=</span> test_df.pivot(index<span class="op">=</span><span class="st">'date'</span>, columns<span class="op">=</span><span class="st">'Company'</span>, values<span class="op">=</span><span class="st">'return'</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>stock_df[(stock_df[<span class="st">'date'</span>] <span class="op">&lt;=</span> <span class="st">'2020-12-30'</span>)][<span class="st">'date'</span>].unique()</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="co">#Cumulative portfolio value</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cumulative_value(weights, returns_weights):</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#cumulative product over time for each asset</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    cumprod_val <span class="op">=</span> returns_weights.cumprod()</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#daily portfolio value</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    cumul_val <span class="op">=</span> cumprod_val.dot(weights)</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cumul_val</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="co">#Annualized return</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> annualized_return(cumul_val):</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> <span class="bu">len</span>(cumul_val)</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">#the final cumulative value of the portfolio at day T</span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>    final_val <span class="op">=</span> cumul_val.iloc[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">#assume there are 252 trading days in a year</span></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> final_val<span class="op">**</span>(<span class="dv">252</span><span class="op">/</span>T) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a><span class="co">#Realized variance of the daily return</span></span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> realized_var(cumul_val):</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>    daily_ret <span class="op">=</span> cumul_val.pct_change()</span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> daily_ret.var()</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a><span class="co">#Apply to training and test sets for each portfolio</span></span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {}</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t, optim_weights <span class="kw">in</span> portfolios.items():</span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Cumulative portfolio value</span></span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>    train_cumul_val <span class="op">=</span> cumulative_value(optim_weights, train_wide_ret)</span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a>    test_cumul_val  <span class="op">=</span> cumulative_value(optim_weights, test_wide_ret)</span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Annualized return</span></span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a>    ann_ret_train <span class="op">=</span> annualized_return(train_cumul_val)</span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a>    ann_ret_test  <span class="op">=</span> annualized_return(test_cumul_val)</span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Realized variance</span></span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>    var_train <span class="op">=</span> realized_var(train_cumul_val)</span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>    var_test  <span class="op">=</span> realized_var(test_cumul_val)</span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Maximum allocation</span></span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a>    names_cols <span class="op">=</span> train_wide_ret.columns</span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a>    max_idx <span class="op">=</span> np.argmax(optim_weights)</span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true" tabindex="-1"></a>    max_asset <span class="op">=</span> names_cols[max_idx]</span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true" tabindex="-1"></a>    max_weight <span class="op">=</span> optim_weights[max_idx]</span>
<span id="cb28-47"><a href="#cb28-47" aria-hidden="true" tabindex="-1"></a>    <span class="co">#sum of absolute weights</span></span>
<span id="cb28-48"><a href="#cb28-48" aria-hidden="true" tabindex="-1"></a>    leverage <span class="op">=</span> np.<span class="bu">sum</span>(np.<span class="bu">abs</span>(optim_weights))</span>
<span id="cb28-49"><a href="#cb28-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-50"><a href="#cb28-50" aria-hidden="true" tabindex="-1"></a>    results[t] <span class="op">=</span> {</span>
<span id="cb28-51"><a href="#cb28-51" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Optimal weights'</span>: optim_weights,</span>
<span id="cb28-52"><a href="#cb28-52" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Train: Cumulative value'</span>: train_cumul_val,</span>
<span id="cb28-53"><a href="#cb28-53" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Test: Cumulative value'</span>: test_cumul_val,</span>
<span id="cb28-54"><a href="#cb28-54" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Train: Annualized return'</span>: ann_ret_train,</span>
<span id="cb28-55"><a href="#cb28-55" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Test: Annualized return'</span>: ann_ret_test,</span>
<span id="cb28-56"><a href="#cb28-56" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Train: Realized variance'</span>: var_train,</span>
<span id="cb28-57"><a href="#cb28-57" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Test: Realized variance'</span>: var_test,</span>
<span id="cb28-58"><a href="#cb28-58" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Asset with the maximum allocation weight'</span>: max_asset,</span>
<span id="cb28-59"><a href="#cb28-59" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Its weight'</span>: max_weight,</span>
<span id="cb28-60"><a href="#cb28-60" aria-hidden="true" tabindex="-1"></a>        <span class="st">'The initial leverage'</span>: leverage</span>
<span id="cb28-61"><a href="#cb28-61" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb28-62"><a href="#cb28-62" aria-hidden="true" tabindex="-1"></a><span class="co">#Print metrics</span></span>
<span id="cb28-63"><a href="#cb28-63" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t, r <span class="kw">in</span> results.items():</span>
<span id="cb28-64"><a href="#cb28-64" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"For a target return of"</span>, t)</span>
<span id="cb28-65"><a href="#cb28-65" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Training annualized return:"</span>, np.<span class="bu">round</span>(r[<span class="st">'Train: Annualized return'</span>], <span class="dv">4</span>))</span>
<span id="cb28-66"><a href="#cb28-66" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Training risk (variance):"</span>, np.<span class="bu">round</span>(r[<span class="st">'Train: Realized variance'</span>], <span class="dv">6</span>))</span>
<span id="cb28-67"><a href="#cb28-67" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Testing annualized return:"</span>, np.<span class="bu">round</span>(r[<span class="st">'Test: Annualized return'</span>], <span class="dv">4</span>))</span>
<span id="cb28-68"><a href="#cb28-68" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Testing risk (variance):"</span>, np.<span class="bu">round</span>(r[<span class="st">'Test: Realized variance'</span>], <span class="dv">6</span>))</span>
<span id="cb28-69"><a href="#cb28-69" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Max-weight asset:"</span>, r[<span class="st">'Asset with the maximum allocation weight'</span>], <span class="st">"with weight"</span>, np.<span class="bu">round</span>(r[<span class="st">'Its weight'</span>], <span class="dv">4</span>))</span>
<span id="cb28-70"><a href="#cb28-70" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Initial leverage:"</span>, np.<span class="bu">round</span>(r[<span class="st">'The initial leverage'</span>], <span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>For a target return of 1.05
Training annualized return: 0.0478
Training risk (variance): 6.3e-05
Testing annualized return: -0.0085
Testing risk (variance): 4.3e-05
Max-weight asset: TLT with weight 0.0429
Initial leverage: 2.5499
For a target return of 1.1
Training annualized return: 0.0865
Training risk (variance): 6.6e-05
Testing annualized return: -0.0039
Testing risk (variance): 4.1e-05
Max-weight asset: TLT with weight 0.0425
Initial leverage: 2.5699
For a target return of 1.2
Training annualized return: 0.1564
Training risk (variance): 8.3e-05
Testing annualized return: 0.0068
Testing risk (variance): 3.7e-05
Max-weight asset: TLT with weight 0.0416
Initial leverage: 2.6532</code></pre>
</div>
</div>
<div id="69fb8eed" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Plot the cumulative value of each portfolio over time</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">8</span>))</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> r, res <span class="kw">in</span> results.items():</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    plt.plot(res[<span class="st">'Train: Cumulative value'</span>].index, res[<span class="st">'Train: Cumulative value'</span>], label<span class="op">=</span><span class="ss">f'Train r=</span><span class="sc">{</span>r<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training test, Cumulative Value'</span>)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Cumulative Value'</span>)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Date'</span>)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">8</span>))</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> r, res <span class="kw">in</span> results.items():</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>  plt.plot(res[<span class="st">'Test: Cumulative value'</span>].index, res[<span class="st">'Test: Cumulative value'</span>], label<span class="op">=</span><span class="ss">f'Test r=</span><span class="sc">{</span>r<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Testing set, Cumulative Value'</span>)</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Cumulative Value'</span>)</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Date'</span>)</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Applications_of_Least_Squares_files/figure-html/cell-16-output-1.png" width="812" height="671" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Applications_of_Least_Squares_files/figure-html/cell-16-output-2.png" width="820" height="671" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ol start="3" type="a">
<li>It is well known that optimal portfolios constructed using the Markowitz procedure perform much more poorly out of sample compared to in sample. This is due to a variety of reasons, one of which is that the procedure assumes that future returns are equal to past returns, another that the correlation structure of the market might change over time, and finally, when there are many assets there is the potential for overfitting. Repeat the previous problem but introduce a ridge regression/<span class="math inline">\(l_2\)</span> norm penalty term to the objective function, with a hyperparameter <span class="math inline">\(\lambda\)</span> governing the size of the penalty term.</li>
</ol>
<p>Specifically, you will select 10 positive values of <span class="math inline">\(\lambda\)</span> on a log scale between <span class="math inline">\(1e-1\)</span> and <span class="math inline">\(10\)</span> and for each value of <span class="math inline">\(\lambda\)</span> solve the following penalized regression problem:</p>
<p><span class="math display">\[
\begin{aligned}
    \min_{w} w^T(\Gamma+\lambda I) w ,\\
    w^T\mu = r,\\
    \sum_{i=1}^n w_i = 1
\end{aligned}
\]</span></p>
<p>for just the single value of <span class="math inline">\(r=20\%\)</span>. Then calculate the performance of each of these regularized Markowitz strategies on both the training and test datasets and plot the the return of the portfolios over both the training and testing period.</p>
<p>For each portfolio, also report:</p>
<ul>
<li>The annualized return on the training and test sets;</li>
<li>The risk on the training and test sets;</li>
<li>The maximum allocation weight and the asset with maximum allocation;</li>
<li>The initial leverage</li>
</ul>
<p>Comment on how the different values of <span class="math inline">\(\lambda\)</span> changed the optimal portfolios and the difference between in-sample and out-of-sample return and variance.</p>
<p><strong>Solution:</strong></p>
<p>In this problem, instead of minimizing <span class="math inline">\(\mathbf{x}^T\Gamma \mathbf{x}\)</span>, we minimize <span class="math inline">\(w^T(\Gamma+\lambda I) w\)</span> with the same constraints (target return, sum of weights). In Python, we create 10 positive values of <span class="math inline">\(\lambda\)</span> on a log scale between <span class="math inline">\(1e-1\)</span> and <span class="math inline">\(10\)</span> with np.logspace(). Using similar functions as in part a, we find the portfolio weights (r=1.2) for ten different <span class="math inline">\(\lambda\)</span> values, and apply those weights (without rebalancing) to the training and testing set. After, we compute metrics for both sets: the cumulative portfolio value over time, the annualized return, the risk, the maximum allocation weight and the asset with maximum allocation, the initial leverage. We also build a training plot to show how each ridge‐regularized portfolio (color‐coded by <span class="math inline">\(\lambda\)</span>) evolves in the training period, and a test plot to show how the same portfolios (with their weights fixed from training) perform out of sample from 2023–2024.</p>
<p>Despite aiming for r=1.2, the actual realized annualized return on the training data hovers around ~14–15%, likely due to estimation error, market fluctuations, or portfolio constraints affecting the realized performance. In the test set, it varies from ~16–20%, depending on <span class="math inline">\(\lambda\)</span>. While the training variance is fairly stable, the testing annualized returns improve as <span class="math inline">\(\lambda\)</span> grows. As <span class="math inline">\(\lambda\)</span> grows, the portfolio weights shrink in magnitude, reducing extreme bets and short positions, leading to a more diversified allocation. It might be that by penalizing large weights we reduce overfitting and yield more robust out‐of‐sample results.The highest weight belongs to MRNA, with a weight of around 0.005–0.007. With very low <span class="math inline">\(\lambda\)</span>, leverage can exceed 1, indicating some negative weights.</p>
<p>For the training set, all solutions manage a similar final portfolio value around 1.8–1.9× the initial investment by 2022, giving ~14–15% annualized. For the test set, the unchanging weights are then applied from 2023 onward. Larger‐<span class="math inline">\(\lambda\)</span> portfolios avoid overfitting, posting higher returns (up to ~0.20) and a moderate daily variance. The smaller‐<span class="math inline">\(\lambda\)</span> portfolios typically have more pronounced bets that might not pay off as well out of sample.</p>
<p>Training plot has all ten lines close together, indicating that they end up with a final value near 1.8 or 1.9. The lines nearly overlap because the penalty doesn’t drastically change the in‐sample path. Test plot shows us the results after we applied the same weights to new market data. We see slightly more spread between the lines, especially as <span class="math inline">\(\lambda\)</span> increases.</p>
<p>The ridge regression approach, compared to the solutions in parts (a) and (b), helps mitigate overfitting by penalizing extreme portfolio weights. The risk is not dramatically smaller in training, but the test return is higher. Low <span class="math inline">\(\lambda\)</span> leaves the solution closer to the classic Markowitz approach, with a potential overfitting. Higher <span class="math inline">\(\lambda\)</span> regularizes the portfolio weights, resulting in more stable out‐of‐sample performance and leverage ~1.</p>
<div id="6103bc1f" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Ridge optimization</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> portfolio_optimize_ridge(mu, Gamma, target_return, lam):</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>    n_companies <span class="op">=</span> <span class="bu">len</span>(mu)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Ridge-penalized covariance</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    Gamma_ridge <span class="op">=</span> Gamma <span class="op">+</span> lam <span class="op">*</span> np.eye(n_companies)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Variance</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> portfolio_var(w):</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> w <span class="op">@</span> Gamma_ridge <span class="op">@</span> w</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>    constraints <span class="op">=</span> [</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>        {<span class="st">'type'</span>: <span class="st">'eq'</span>, <span class="st">'fun'</span>: <span class="kw">lambda</span> w: w <span class="op">@</span> mu <span class="op">-</span> target_return},</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>        {<span class="st">'type'</span>: <span class="st">'eq'</span>, <span class="st">'fun'</span>: <span class="kw">lambda</span> w: np.<span class="bu">sum</span>(w) <span class="op">-</span> <span class="dv">1</span>}</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Initial condition</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>    initial_cond <span class="op">=</span> np.array([<span class="dv">1</span><span class="op">/</span>n_companies] <span class="op">*</span> n_companies)</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>    bounds <span class="op">=</span> <span class="bu">tuple</span>((<span class="va">None</span>, <span class="va">None</span>) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_companies))</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">#The optimization problem</span></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> minimize(portfolio_var, initial_cond, bounds <span class="op">=</span> bounds, method<span class="op">=</span><span class="st">'SLSQP'</span>, constraints<span class="op">=</span>constraints)</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result.x</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a><span class="co">#0.1 to 10</span></span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>lambda_val <span class="op">=</span> np.logspace(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">10</span>)  <span class="co"># 0.1 to 10</span></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>target_return <span class="op">=</span> <span class="fl">1.2</span></span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a><span class="co">#Keep data</span></span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>ridge_portfolios <span class="op">=</span> {}</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>company_name <span class="op">=</span> train_wide.columns</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"For a target return of 1.2: "</span>)</span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> lam <span class="kw">in</span> lambda_val:</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>    optimal_weights_ridge <span class="op">=</span> portfolio_optimize_ridge(mu, Gamma, target_return, lam)</span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>    ridge_portfolios[lam] <span class="op">=</span> optimal_weights_ridge</span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Print results in readable format</span></span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>    optimal_weights_ridge_rounded <span class="op">=</span> np.<span class="bu">round</span>(optimal_weights_ridge, <span class="dv">4</span>)</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a>    optimal_portfolio_ridge <span class="op">=</span> pd.DataFrame({<span class="st">'Company'</span>: company_name, <span class="st">'Optimal weight'</span>: optimal_weights_ridge_rounded})</span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"For lambda: "</span>, lam)</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(optimal_portfolio_ridge)</span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Sum of weights, should be 1:"</span>, np.<span class="bu">sum</span>(optimal_weights_ridge))</span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Portfolio expected return:"</span>, optimal_weights_ridge.T <span class="op">@</span> mu)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>For a target return of 1.2: 
For lambda:  0.1
    Company  Optimal weight
0         A          0.0027
1      AAPL          0.0024
2      ABBV          0.0037
3      ABEV          0.0016
4       ABT          0.0027
..      ...             ...
466     YUM          0.0025
467     ZBH          0.0018
468      ZM          0.0032
469      ZS          0.0030
470     ZTS          0.0022

[471 rows x 2 columns]
Sum of weights, should be 1: 1.0
Portfolio expected return: 1.199999999925958
For lambda:  0.16681005372000587
    Company  Optimal weight
0         A          0.0026
1      AAPL          0.0024
2      ABBV          0.0033
3      ABEV          0.0015
4       ABT          0.0025
..      ...             ...
466     YUM          0.0024
467     ZBH          0.0018
468      ZM          0.0027
469      ZS          0.0029
470     ZTS          0.0021

[471 rows x 2 columns]
Sum of weights, should be 1: 0.9999999999999999
Portfolio expected return: 1.2000000000078472
For lambda:  0.2782559402207124
    Company  Optimal weight
0         A          0.0025
1      AAPL          0.0025
2      ABBV          0.0030
3      ABEV          0.0015
4       ABT          0.0023
..      ...             ...
466     YUM          0.0023
467     ZBH          0.0017
468      ZM          0.0023
469      ZS          0.0029
470     ZTS          0.0020

[471 rows x 2 columns]
Sum of weights, should be 1: 1.0
Portfolio expected return: 1.2000000000155515
For lambda:  0.46415888336127786
    Company  Optimal weight
0         A          0.0025
1      AAPL          0.0025
2      ABBV          0.0029
3      ABEV          0.0015
4       ABT          0.0023
..      ...             ...
466     YUM          0.0022
467     ZBH          0.0017
468      ZM          0.0022
469      ZS          0.0029
470     ZTS          0.0020

[471 rows x 2 columns]
Sum of weights, should be 1: 1.0
Portfolio expected return: 1.199999999992936
For lambda:  0.774263682681127
    Company  Optimal weight
0         A          0.0025
1      AAPL          0.0025
2      ABBV          0.0028
3      ABEV          0.0015
4       ABT          0.0022
..      ...             ...
466     YUM          0.0022
467     ZBH          0.0017
468      ZM          0.0020
469      ZS          0.0029
470     ZTS          0.0020

[471 rows x 2 columns]
Sum of weights, should be 1: 1.0
Portfolio expected return: 1.1999999999846855
For lambda:  1.291549665014884
    Company  Optimal weight
0         A          0.0025
1      AAPL          0.0025
2      ABBV          0.0028
3      ABEV          0.0015
4       ABT          0.0022
..      ...             ...
466     YUM          0.0022
467     ZBH          0.0017
468      ZM          0.0019
469      ZS          0.0029
470     ZTS          0.0020

[471 rows x 2 columns]
Sum of weights, should be 1: 0.9999999999999998
Portfolio expected return: 1.2000000000045332
For lambda:  2.1544346900318834
    Company  Optimal weight
0         A          0.0025
1      AAPL          0.0025
2      ABBV          0.0027
3      ABEV          0.0015
4       ABT          0.0021
..      ...             ...
466     YUM          0.0022
467     ZBH          0.0017
468      ZM          0.0019
469      ZS          0.0029
470     ZTS          0.0020

[471 rows x 2 columns]
Sum of weights, should be 1: 1.0
Portfolio expected return: 1.1999999999934765
For lambda:  3.593813663804626
    Company  Optimal weight
0         A          0.0025
1      AAPL          0.0025
2      ABBV          0.0027
3      ABEV          0.0015
4       ABT          0.0021
..      ...             ...
466     YUM          0.0021
467     ZBH          0.0017
468      ZM          0.0019
469      ZS          0.0029
470     ZTS          0.0020

[471 rows x 2 columns]
Sum of weights, should be 1: 1.0
Portfolio expected return: 1.2000000000009652
For lambda:  5.994842503189409
    Company  Optimal weight
0         A          0.0025
1      AAPL          0.0025
2      ABBV          0.0027
3      ABEV          0.0015
4       ABT          0.0021
..      ...             ...
466     YUM          0.0021
467     ZBH          0.0017
468      ZM          0.0018
469      ZS          0.0029
470     ZTS          0.0019

[471 rows x 2 columns]
Sum of weights, should be 1: 1.0
Portfolio expected return: 1.2000000000108566
For lambda:  10.0
    Company  Optimal weight
0         A          0.0025
1      AAPL          0.0025
2      ABBV          0.0027
3      ABEV          0.0015
4       ABT          0.0021
..      ...             ...
466     YUM          0.0021
467     ZBH          0.0017
468      ZM          0.0018
469      ZS          0.0029
470     ZTS          0.0019

[471 rows x 2 columns]
Sum of weights, should be 1: 1.0
Portfolio expected return: 1.200000000025245</code></pre>
</div>
</div>
<div id="49ac52cf" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Cumulative portfolio value</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cumulative_value(weights, returns_weights):</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">#cumulative product over time for each asset</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    cumprod_val <span class="op">=</span> returns_weights.cumprod()</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">#daily portfolio value</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>    cumul_val <span class="op">=</span> cumprod_val.dot(weights)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cumul_val</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="co">#Annualized return</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> annualized_return(cumul_val):</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> <span class="bu">len</span>(cumul_val)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#the final cumulative value of the portfolio at day T</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>    final_val <span class="op">=</span> cumul_val.iloc[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">#assume there are 252 trading days in a year</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> final_val<span class="op">**</span>(<span class="dv">252</span><span class="op">/</span>T) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a><span class="co">#Realized variance of the daily return</span></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> realized_var(cumul_val):</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>    daily_ret <span class="op">=</span> cumul_val.pct_change()</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> daily_ret.var()</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a><span class="co">#Apply to training and test sets for each portfolio</span></span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>results_ridge <span class="op">=</span> {}</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> lam, optim_weights <span class="kw">in</span> ridge_portfolios.items():</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Cumulative portfolio value</span></span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>    train_cumul_val <span class="op">=</span> cumulative_value(optim_weights, train_wide_ret)</span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>    test_cumul_val  <span class="op">=</span> cumulative_value(optim_weights, test_wide_ret)</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Annualized return</span></span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>    ann_ret_train <span class="op">=</span> annualized_return(train_cumul_val)</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>    ann_ret_test  <span class="op">=</span> annualized_return(test_cumul_val)</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Realized variance</span></span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a>    var_train <span class="op">=</span> realized_var(train_cumul_val)</span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a>    var_test  <span class="op">=</span> realized_var(test_cumul_val)</span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Maximum allocation</span></span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a>    names_cols <span class="op">=</span> train_wide_ret.columns</span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a>    max_idx <span class="op">=</span> np.argmax(optim_weights)</span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a>    max_asset <span class="op">=</span> names_cols[max_idx]</span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a>    max_weight <span class="op">=</span> optim_weights[max_idx]</span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a>    <span class="co">#sum of absolute weights</span></span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a>    leverage <span class="op">=</span> np.<span class="bu">sum</span>(np.<span class="bu">abs</span>(optim_weights))</span>
<span id="cb33-45"><a href="#cb33-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-46"><a href="#cb33-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Store</span></span>
<span id="cb33-47"><a href="#cb33-47" aria-hidden="true" tabindex="-1"></a>    results_ridge[lam] <span class="op">=</span> {</span>
<span id="cb33-48"><a href="#cb33-48" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Optimal weights'</span>: optim_weights,</span>
<span id="cb33-49"><a href="#cb33-49" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Train: Cumulative value'</span>: train_cumul_val,</span>
<span id="cb33-50"><a href="#cb33-50" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Test: Cumulative value'</span>: test_cumul_val,</span>
<span id="cb33-51"><a href="#cb33-51" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Train: Annualized return'</span>: ann_ret_train,</span>
<span id="cb33-52"><a href="#cb33-52" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Test: Annualized return'</span>: ann_ret_test,</span>
<span id="cb33-53"><a href="#cb33-53" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Train: Realized variance'</span>: var_train,</span>
<span id="cb33-54"><a href="#cb33-54" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Test: Realized variance'</span>: var_test,</span>
<span id="cb33-55"><a href="#cb33-55" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Asset with the maximum allocation weight'</span>: max_asset,</span>
<span id="cb33-56"><a href="#cb33-56" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Its weight'</span>: max_weight,</span>
<span id="cb33-57"><a href="#cb33-57" aria-hidden="true" tabindex="-1"></a>        <span class="st">'The initial leverage'</span>: leverage</span>
<span id="cb33-58"><a href="#cb33-58" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb33-59"><a href="#cb33-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-60"><a href="#cb33-60" aria-hidden="true" tabindex="-1"></a><span class="co">#Print metrics</span></span>
<span id="cb33-61"><a href="#cb33-61" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t, r <span class="kw">in</span> results_ridge.items():</span>
<span id="cb33-62"><a href="#cb33-62" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"For lambda"</span>, t)</span>
<span id="cb33-63"><a href="#cb33-63" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Training annualized return:"</span>, np.<span class="bu">round</span>(r[<span class="st">'Train: Annualized return'</span>], <span class="dv">4</span>))</span>
<span id="cb33-64"><a href="#cb33-64" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Training risk (variance):"</span>, np.<span class="bu">round</span>(r[<span class="st">'Train: Realized variance'</span>], <span class="dv">6</span>))</span>
<span id="cb33-65"><a href="#cb33-65" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Testing annualized return:"</span>, np.<span class="bu">round</span>(r[<span class="st">'Test: Annualized return'</span>], <span class="dv">4</span>))</span>
<span id="cb33-66"><a href="#cb33-66" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Testing risk (variance):"</span>, np.<span class="bu">round</span>(r[<span class="st">'Test: Realized variance'</span>], <span class="dv">6</span>))</span>
<span id="cb33-67"><a href="#cb33-67" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Max-weight asset:"</span>, r[<span class="st">'Asset with the maximum allocation weight'</span>], <span class="st">"with weight"</span>, np.<span class="bu">round</span>(r[<span class="st">'Its weight'</span>], <span class="dv">4</span>))</span>
<span id="cb33-68"><a href="#cb33-68" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Initial leverage:"</span>, np.<span class="bu">round</span>(r[<span class="st">'The initial leverage'</span>], <span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>For lambda 0.1
Training annualized return: 0.1458
Training risk (variance): 0.000222
Testing annualized return: 0.1667
Testing risk (variance): 5.1e-05
Max-weight asset: MRNA with weight 0.007
Initial leverage: 1.0068
For lambda 0.16681005372000587
Training annualized return: 0.1458
Training risk (variance): 0.000238
Testing annualized return: 0.1779
Testing risk (variance): 5.5e-05
Max-weight asset: MRNA with weight 0.0065
Initial leverage: 1.0028
For lambda 0.2782559402207124
Training annualized return: 0.1458
Training risk (variance): 0.000252
Testing annualized return: 0.1874
Testing risk (variance): 5.9e-05
Max-weight asset: MRNA with weight 0.0062
Initial leverage: 1.0005
For lambda 0.46415888336127786
Training annualized return: 0.1458
Training risk (variance): 0.000257
Testing annualized return: 0.1907
Testing risk (variance): 6.1e-05
Max-weight asset: MRNA with weight 0.006
Initial leverage: 1.0
For lambda 0.774263682681127
Training annualized return: 0.1458
Training risk (variance): 0.000263
Testing annualized return: 0.1947
Testing risk (variance): 6.2e-05
Max-weight asset: MRNA with weight 0.0059
Initial leverage: 1.0
For lambda 1.291549665014884
Training annualized return: 0.1458
Training risk (variance): 0.000264
Testing annualized return: 0.1953
Testing risk (variance): 6.3e-05
Max-weight asset: MRNA with weight 0.0059
Initial leverage: 1.0
For lambda 2.1544346900318834
Training annualized return: 0.1458
Training risk (variance): 0.000266
Testing annualized return: 0.1964
Testing risk (variance): 6.3e-05
Max-weight asset: MRNA with weight 0.0058
Initial leverage: 1.0
For lambda 3.593813663804626
Training annualized return: 0.1458
Training risk (variance): 0.000268
Testing annualized return: 0.1973
Testing risk (variance): 6.3e-05
Max-weight asset: MRNA with weight 0.0058
Initial leverage: 1.0
For lambda 5.994842503189409
Training annualized return: 0.1458
Training risk (variance): 0.000269
Testing annualized return: 0.198
Testing risk (variance): 6.4e-05
Max-weight asset: MRNA with weight 0.0058
Initial leverage: 1.0
For lambda 10.0
Training annualized return: 0.1458
Training risk (variance): 0.000269
Testing annualized return: 0.1978
Testing risk (variance): 6.4e-05
Max-weight asset: MRNA with weight 0.0058
Initial leverage: 1.0</code></pre>
</div>
</div>
<div id="d96875b3" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Plot the cumulative value of each portfolio over time</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">8</span>))</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> r, res <span class="kw">in</span> results_ridge.items():</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    plt.plot(res[<span class="st">'Train: Cumulative value'</span>].index, res[<span class="st">'Train: Cumulative value'</span>], label<span class="op">=</span><span class="ss">f'Train r=</span><span class="sc">{</span>r<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training test, Cumulative Value, Ridge regression'</span>)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Cumulative Value'</span>)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Date'</span>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">8</span>))</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> r, res <span class="kw">in</span> results_ridge.items():</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>  plt.plot(res[<span class="st">'Test: Cumulative value'</span>].index, res[<span class="st">'Test: Cumulative value'</span>], label<span class="op">=</span><span class="ss">f'Test r=</span><span class="sc">{</span>r<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Testing set, Cumulative Value, Ridge regression'</span>)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Cumulative Value'</span>)</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Date'</span>)</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Applications_of_Least_Squares_files/figure-html/cell-19-output-1.png" width="812" height="671" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Applications_of_Least_Squares_files/figure-html/cell-19-output-2.png" width="812" height="671" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="reference" class="level2">
<h2 class="anchored" data-anchor-id="reference">Reference</h2>
<ol type="1">
<li><p>Boyd, S. (2018). <em>Introduction to applied linear algebra: Vectors, matrices, and least squares</em>. Cambridge University Press. <a href="https://web.stanford.edu/~boyd/vmls/vmls.pdf" class="uri">https://web.stanford.edu/~boyd/vmls/vmls.pdf</a></p></li>
<li><p>Boyd, S., &amp; Vandenberghe, L. (2004). <em>Convex optimization</em>. Cambridge University Press. <a href="https://doi.org/10.1017/CBO9780511804441" class="uri">https://doi.org/10.1017/CBO9780511804441</a></p></li>
<li><p>MOSEK ApS. (n.d.). Markowitz Portfolio Optimization. In Portfolio Optimization Cookbook 1.6.0. Retrieved from <a href="https://docs.mosek.com/portfolio-cookbook/markowitz.html" class="uri">https://docs.mosek.com/portfolio-cookbook/markowitz.html</a></p></li>
<li><p>Duong, E. (2023, May 15). Python-Powered Portfolio Optimization: Achieving Target Returns Through Weight Optimization. Medium. Retrieved from <a href="https://medium.com/" class="uri">https://medium.com/</a><span class="citation" data-cites="ethan.duong1120/python-powered-portfolio-optimization-achieving-target-returns-through-weight-optimization-fc5163e5c9c6">@ethan.duong1120/python-powered-portfolio-optimization-achieving-target-returns-through-weight-optimization-fc5163e5c9c6</span></p></li>
<li><p>Ziegler, G. (2023, July 10). Constructing Markowitz’s Efficient Frontier with Python and Streamlit. Medium. Retrieved from <a href="https://medium.com/" class="uri">https://medium.com/</a><span class="citation" data-cites="guilherme.ziegler/constructing-markowitzs-efficient-frontier-with-python-and-streamlit-f99a495fb74d">@guilherme.ziegler/constructing-markowitzs-efficient-frontier-with-python-and-streamlit-f99a495fb74d</span></p></li>
<li><p>Virtanen, P., et al.&nbsp;(2020). SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python. Nature Methods, 17, 261–272. <a href="https://doi.org/10.1038/s41592-019-0686-2" class="uri">https://doi.org/10.1038/s41592-019-0686-2</a></p></li>
</ol>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>